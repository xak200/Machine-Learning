import numpy as np
import matplotlib.pyplot as plt
import random
from sklearn import tree
from sklearn.externals.six import StringIO
import pydot_ng as pydot

def stripCommas(fileName):
    f = open('ps4_data/' + fileName, 'r')
    last = 12
    countLines = 0
    newListFile = []
    for line in f:
        line = line.replace(' ', '')
        newLine = line.split(',')
        newLine[last] = newLine[last].strip()       #strip newline character
        newListFile.append(newLine)
        countLines += 1
    f.close()
    return (newListFile, countLines)

def addToDict(sample, index, totalDict):
    if sample[index] in totalDict:
        value = totalDict[sample[index]]
        value += 1
        totalDict[sample[index]] = value
    else:
        totalDict[sample[index]] = 1
    return

def findMeansAndModes(newListFile, lineCount):
    aggregate0 = 0
    aggregate8 = 0
    aggregate9 = 0
    aggregate10 = 0
    totalDict1 = {}
    totalDict2 = {}
    totalDict3 = {}
    totalDict4 = {}
    totalDict5 = {}
    totalDict6 = {}
    totalDict7 = {}
    totalDict11 = {}
    for sample in newListFile:
        if (sample[0] != '?'):
            aggregate0 += int(sample[0])
        if (sample[8] != '?'):
            aggregate8 += int(sample[8])
        if (sample[9] != '?'):
            aggregate9 += int(sample[9])
        if (sample[10] != '?'):
            aggregate10 += int(sample[10])
        addToDict(sample, 1, totalDict1)
        addToDict(sample, 2, totalDict2)
        addToDict(sample, 3, totalDict3)
        addToDict(sample, 4, totalDict4)
        addToDict(sample, 5, totalDict5)
        addToDict(sample, 6, totalDict6)
        addToDict(sample, 7, totalDict7)
        addToDict(sample, 11, totalDict11)
    mode1 = max(totalDict1, key=lambda i: totalDict1[i])
    mode2 = max(totalDict2, key=lambda i: totalDict2[i])
    mode3 = max(totalDict3, key=lambda i: totalDict3[i])
    mode4 = max(totalDict4, key=lambda i: totalDict4[i])
    mode5 = max(totalDict5, key=lambda i: totalDict5[i])
    mode6 = max(totalDict6, key=lambda i: totalDict6[i])
    mode7 = max(totalDict7, key=lambda i: totalDict7[i])
    mode11 = max(totalDict11, key=lambda i: totalDict11[i])
    mean0 = format(aggregate0 / lineCount, '.2f')
    mean8 = format(aggregate8 / lineCount, '.2f')
    mean9 = format(aggregate9 / lineCount, '.2f')
    mean10 = format(aggregate10 / lineCount, '.2f')
    meansAndModes = [mean0, mode1, mode2, mode3, mode4, mode5, mode6, mode7, mean8, mean9, mean10, mode11]
    return meansAndModes

def replaceQuestion(newListFile, meansAndModes):
    for sample in newListFile:
        for i in range(12):
            if (sample[i] == '?'):
                sample[i] = meansAndModes[i]
    return newListFile

def expandCategoricalFeatures(noQuestionFile):
    originalFeatures =[['age', 'numeric'],
                       ['workclass', 'categorical', 8,
                        ['Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov', 'State-gov',
                         'Without-pay', 'Never-worked']],
                       ['education', 'categorical', 16,
                        ['Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', '9th',
                         '7th-8th', '12th', 'Masters', '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool']],
                       ['marital status', 'categorical', 7,
                        ['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed', 'Married-spouse-absent',
                         'Married-AF-spouse']],
                       ['occupation', 'categorical', 14,
                        ['Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial', 'Prof-specialty',
                         'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving',
                         'Priv-house-serv', 'Protective-serv', 'Armed-Forces']],
                       ['relationship', 'categorical', 6,
                        ['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried']],
                       ['race', 'categorical', 5,
                        ['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black']],
                       ['sex', 'categorical', 2, ['Female', 'Male']],
                       ['capital gain', 'numeric'],
                       ['capital loss', 'numeric'],
                       ['hours per week', 'numeric'],
                       ['native country', 'categorical', 41,
                        ['United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany',
                         'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece', 'South', 'China', 'Cuba', 'Iran',
                         'Honduras', 'Philippines', 'Italy', 'Poland', 'Jamaica', 'Vietnam', 'Mexico', 'Portugal',
                         'Ireland', 'France', 'Dominican-Republic', 'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia',
                         'Hungary', 'Guatemala', 'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador',
                         'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands']]]
    newFeatures = []
    for feature in originalFeatures:
        if (feature[1] == 'numeric'):
            newFeatures.append(feature[0])
        if (feature[1] == 'categorical'):
            for subFeature in feature[3]:
                newFeatureName = feature[0] + ':' + subFeature
                newFeatures.append(newFeatureName)
    return(originalFeatures, newFeatures)

def replaceCategoricalDataAndLabel(noQuestionFile, originalFeatures):
    finalDataMatrix = []
    for sample in noQuestionFile:
        newSample = []
        #go through sample features
        counter = 0
        for datum in sample:
            #if numeric, leave data the same, append to finalDataMatrix
            if (originalFeatures[counter][1] == 'numeric'):
                newSample.append(datum)
            #else if categorical,
            else:
                for feature in originalFeatures[counter][3]:
                    #append 1 when sample element matches originalFeature
                    if (datum == feature):
                        newSample.append(1)
                    #append 0 when doesn't
                    else:
                        newSample.append(0)
            counter += 1
            if (counter == 12):
                if (sample[counter] == '<=50K'):
                    newSample.append(-1)
                else:
                    newSample.append(1)
                break
        finalDataMatrix.append(newSample)
    return (finalDataMatrix)

def splitIntoTrainAndValidate(finalDataMatrix):
    trainLength = round(len(finalDataMatrix) * 0.7)
    random.shuffle(finalDataMatrix)
    trainData = finalDataMatrix[:trainLength]
    validateData = finalDataMatrix[trainLength:]
    trainData, trainLabel = splitFeatureAndLabel(trainData)
    validateData, validateLabel = splitFeatureAndLabel(validateData)
    return(trainData, trainLabel, validateData, validateLabel)

def splitFeatureAndLabel(data):
    featureVectorList = []
    labelList = []
    for person in data:
        newPerson = []
        labelList.append(person[len(person) - 1])
        for i in range(len(person)):
            if ( i < len(person) - 1):
                newPerson.append(person[i])
        featureVectorList.append(newPerson)
    return (featureVectorList, labelList)

def runTree(trainData, trainLabel, validateData, validateLabel):
    maxDepth = list(range(1, 31))
    minSamplesLeaf = list(range(1, 51))
    trainAccuracyDepth = []
    validateAccuracyDepth = []
    trainAccuracyLeaves = []
    validateAccuracyLeaves = []
    for num in maxDepth:
        numMistakes = 0
        clf = tree.DecisionTreeClassifier(max_depth=num)
        clf = clf.fit(trainData, trainLabel)
        trainPredict = clf.predict(trainData)
        for i in range(len(trainPredict)):
            if (trainPredict[i] != trainLabel[i]):
                numMistakes += 1
        trainError = (numMistakes/(len(trainPredict)))
        trainAccuracyDepth.append(1 - trainError)
        numMistakes = 0
        validatePredict = clf.predict(validateData)
        for i in range(len(validatePredict)):
            if (validatePredict[i] != validateLabel[i]):
                numMistakes += 1
        validateError = (numMistakes/(len(validatePredict)))
        validateAccuracyDepth.append(1 - validateError)
    #index has value - 1, so return index + 1 to get max-depth value
    print('max accuracy using max_depth =', np.argmax(validateAccuracyDepth) + 1)
    for num2 in minSamplesLeaf:
        numMistakes = 0
        clf = tree.DecisionTreeClassifier(min_samples_leaf=num2)
        clf = clf.fit(trainData, trainLabel)
        trainPredict = clf.predict(trainData)
        for i in range(len(trainPredict)):
            if (trainPredict[i] != trainLabel[i]):
                numMistakes += 1
        trainError = (numMistakes/(len(trainPredict)))
        trainAccuracyLeaves.append(1 - trainError)
        numMistakes = 0
        validatePredict = clf.predict(validateData)
        for i in range(len(validatePredict)):
            if (validatePredict[i] != validateLabel[i]):
                numMistakes += 1
        validateError = (numMistakes/(len(validatePredict)))
        validateAccuracyLeaves.append(1 - validateError)
    #index has value - 1, so return index + 1 to get min-samples-leaf value
    print('max accuracy using min_samples_leaf =', np.argmax(validateAccuracyLeaves) + 1)
    visualizeTree(trainData, trainLabel)
    plotEverything(trainAccuracyDepth, validateAccuracyDepth, trainAccuracyLeaves, validateAccuracyLeaves, maxDepth, minSamplesLeaf)

def plotEverything(trainAccuracyDepth, validateAccuracyDepth, trainAccuracyLeaves, validateAccuracyLeaves, maxDepth, minSamplesLeaf):
    plt.subplot(211)
    trainDepth, = plt.plot(maxDepth, trainAccuracyDepth, 'r--', label='Train Accuracy')
    validateDepth, = plt.plot(maxDepth, validateAccuracyDepth, 'b--', label='Validate Accuracy')
    plt.ylabel('Accuracy rates')
    plt.xlabel('max_depth parameter')
    plt.ylim(0.5, 1.6)
    plt.legend(handles=[trainDepth, validateDepth])

    plt.subplot(212)
    trainLeaf, = plt.plot(minSamplesLeaf, trainAccuracyLeaves, 'r--', label='Train Accuracy')
    validateLeaf, = plt.plot(minSamplesLeaf, validateAccuracyLeaves, 'b--', label='Validate Accuracy')
    plt.ylabel('Accuracy rates')
    plt.xlabel('min_samples_leaf parameter')
    plt.ylim(0.5, 1.6)
    plt.legend(handles=[trainLeaf, validateLeaf])

    plt.show()

def evaluateTestData(trainData, trainLabel, testData, testLabel):
    clf = tree.DecisionTreeClassifier(max_depth=10, min_samples_leaf=16)
    clf = clf.fit(trainData, trainLabel)
    testPredict = clf.predict(testData)
    numMistakes = 0
    for i in range(len(testPredict)):
        if (testPredict[i] != testLabel[i]):
            numMistakes += 1
    testError = (numMistakes/(len(testPredict)))
    print('test performance: ', 1 - testError)

def visualizeTree(trainData, trainLabel):
    clf = tree.DecisionTreeClassifier(max_depth=10, min_samples_leaf=16)
    clf = clf.fit(trainData, trainLabel)
    dot_data = StringIO()
    tree.export_graphviz(clf, out_file=dot_data)
    #pydot not compatible with python 3.5
    #graph = pydot.graph_from_dot_data(dot_data.getvalue())
    #graph.write_pdf('tree.pdf')

def runIt():
    #2a
    newListFile, lineCount = stripCommas('adult_train.txt')
    meansAndModes = findMeansAndModes(newListFile, lineCount)
    noQuestionFile = replaceQuestion(newListFile, meansAndModes)

    #2b
    originalFeatures, newFeatures = expandCategoricalFeatures(noQuestionFile)
    finalDataMatrix = replaceCategoricalDataAndLabel(noQuestionFile, originalFeatures)
    trainData, trainLabel, validateData, validateLabel = splitIntoTrainAndValidate(finalDataMatrix)

    #2c
    runTree(trainData, trainLabel, validateData, validateLabel)

    #2d - to evaluate test data
    trainData, trainLabel = splitFeatureAndLabel(finalDataMatrix)
    newListFile, lineCount = stripCommas('adult_test.txt')
    noQuestionFile = replaceQuestion(newListFile, meansAndModes)
    finalDataMatrix = replaceCategoricalDataAndLabel(noQuestionFile, originalFeatures)
    testData, testLabel = splitFeatureAndLabel(finalDataMatrix)
    evaluateTestData(trainData, trainLabel, testData, testLabel)


runIt()